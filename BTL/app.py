# app.py
import re
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st
import joblib
from collections import Counter
from sklearn import tree
from sklearn.metrics import roc_curve, auc
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

sns.set_style("whitegrid")

# ======================
# 1. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
# ======================
def clean_text(s):
    if not isinstance(s, str):
        return ""
    s = s.lower()
    s = re.sub(r"http\S+|www\S+|https\S+", " ", s)     # URL
    s = re.sub(r"\S+@\S+", " ", s)                     # Email
    s = re.sub(r"\+?\d[\d\s\-]{5,}\d", " ", s)         # Sá»‘ Ä‘iá»‡n thoáº¡i
    s = re.sub(r"[^a-z0-9\s]", " ", s)                 # KÃ½ tá»± Ä‘áº·c biá»‡t
    s = re.sub(r"\s+", " ", s).strip()
    return s

def load_and_prepare(path):
    df = pd.read_csv(path, encoding="utf-8")
    df['text'] = df['sms']  # Ä‘á»“ng nháº¥t cá»™t dÃ¹ng cho pipeline
    df['text_clean'] = df['sms'].apply(clean_text)
    df['len_char'] = df['sms'].apply(lambda x: len(str(x)))
    df['len_word'] = df['sms'].apply(lambda x: len(str(x).split()))
    df['has_number'] = df['sms'].str.contains(r"\d").astype(int)
    df['has_special'] = df['sms'].str.contains(r"[^a-zA-Z0-9\s]").astype(int)
    return df

# ======================
# 2. EDA (hiá»ƒn thá»‹ trong Streamlit)
# ======================
def exploratory_data_analysis_streamlit(df):
    # PhÃ¢n bá»‘ nhÃ£n
    label_counts = df['label'].value_counts().sort_index()
    label_percent = (label_counts / label_counts.sum() * 100).round(2)

    st.subheader("ğŸ“Š PhÃ¢n bá»‘ nhÃ£n (Count & Percent)")
    label_df = pd.DataFrame({
        "Label": label_counts.index.astype(str),
        "Count": label_counts.values,
        "Percent (%)": label_percent.values
    }).set_index("Label")
    st.table(label_df)

    # Biá»ƒu Ä‘á»“ cá»™t (Count)
    fig, ax = plt.subplots(figsize=(4,3))
    sns.barplot(x=label_counts.index.astype(str), y=label_counts.values, palette="viridis", ax=ax)
    ax.set_title("Sá»‘ lÆ°á»£ng theo nhÃ£n")
    ax.set_xlabel("Label (0 = Ham, 1 = Spam)")
    ax.set_ylabel("Sá»‘ lÆ°á»£ng")
    st.pyplot(fig)

    # Biá»ƒu Ä‘á»“ bÃ¡nh (Percent)
    fig2, ax2 = plt.subplots(figsize=(4,3))
    colors = ["#4CAF50", "#F44336"] if len(label_percent) == 2 else None
    ax2.pie(label_percent.values, labels=label_percent.index.astype(str),
            autopct='%1.1f%%', startangle=90, colors=colors)
    ax2.set_title("Tá»· lá»‡ pháº§n trÄƒm theo nhÃ£n")
    ax2.axis('equal')
    st.pyplot(fig2)

    # Äá»™ dÃ i tin nháº¯n
    df['msg_len'] = df['text'].apply(len)
    st.subheader("ğŸ“ˆ PhÃ¢n phá»‘i Ä‘á»™ dÃ i tin nháº¯n")
    fig3, ax3 = plt.subplots(figsize=(4,3))
    sns.histplot(df['msg_len'], bins=50, kde=True, ax=ax3)
    ax3.set_xlabel("Äá»™ dÃ i tin nháº¯n")
    ax3.set_ylabel("Táº§n suáº¥t")
    st.pyplot(fig3)

    # Boxplot
    st.subheader("ğŸ“¦ Boxplot Ä‘á»™ dÃ i theo nhÃ£n")
    fig4, ax4 = plt.subplots(figsize=(4,3))
    sns.boxplot(x='label', y='msg_len', data=df, palette="Set2", ax=ax4)
    ax4.set_xlabel("Label")
    ax4.set_ylabel("Äá»™ dÃ i tin nháº¯n")
    st.pyplot(fig4)

    # Top tá»« phá»• biáº¿n theo nhÃ£n
    st.subheader("ğŸ”¤ Top 20 tá»« phá»• biáº¿n cá»§a Ham (0) vÃ  Spam (1)")

    # Láº¥y tá»« trong ham (0) vÃ  spam (1)
    ham_words = " ".join(df[df['label'] == 0]['text_clean'].astype(str)).split()
    spam_words = " ".join(df[df['label'] == 1]['text_clean'].astype(str)).split()

    # Äáº¿m táº§n suáº¥t
    ham_counts = Counter(ham_words).most_common(20)
    spam_counts = Counter(spam_words).most_common(20)

    # Váº½ biá»ƒu Ä‘á»“
    fig5, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,6))

    if ham_counts:
        words_ham, counts_ham = zip(*ham_counts)
        sns.barplot(x=list(counts_ham), y=list(words_ham), palette="Blues_r", ax=ax1)
        ax1.set_title("Top 20 tá»« - Ham (0)", fontsize=14, fontweight="bold")
        ax1.set_xlabel("Táº§n suáº¥t")
        ax1.set_ylabel("Tá»«")

    if spam_counts:
        words_spam, counts_spam = zip(*spam_counts)
        sns.barplot(x=list(counts_spam), y=list(words_spam), palette="Reds_r", ax=ax2)
        ax2.set_title("Top 20 tá»« - Spam (1)", fontsize=14, fontweight="bold")
        ax2.set_xlabel("Táº§n suáº¥t")
        ax2.set_ylabel("")

    plt.tight_layout()
    st.pyplot(fig5)


    # Tá»· lá»‡ chá»©a sá»‘ / kÃ½ tá»± Ä‘áº·c biá»‡t
    st.subheader("ğŸ” Tá»· lá»‡ chá»©a sá»‘ / kÃ½ tá»± Ä‘áº·c biá»‡t theo nhÃ£n")
    st.write(df.groupby('label')[['has_number', 'has_special']].mean().round(4))

    # BÃ¡o cÃ¡o tá»± Ä‘á»™ng ngáº¯n
    st.subheader("ğŸ“‘ BÃ¡o cÃ¡o EDA tá»± Ä‘á»™ng (tÃ³m táº¯t)")
    report = []
    if label_percent.min() < 30:
        report.append("âš ï¸ Dá»¯ liá»‡u bá»‹ máº¥t cÃ¢n báº±ng nhÃ£n, cÃ¢n nháº¯c oversampling/undersampling.")
    else:
        report.append("âœ… Dá»¯ liá»‡u phÃ¢n bá»‘ khÃ¡ cÃ¢n báº±ng giá»¯a cÃ¡c nhÃ£n.")
    report.append("ğŸ“ˆ Tin nháº¯n thÆ°á»ng ngáº¯n (<200 kÃ½ tá»±).")
    report.append("ğŸ“¦ Spam cÃ³ xu hÆ°á»›ng dÃ i hÆ¡n ham.")
    report.append("ğŸ” Spam cÃ³ xu hÆ°á»›ng chá»©a nhiá»u sá»‘/kÃ½ tá»± Ä‘áº·c biá»‡t hÆ¡n ham.")
    for r in report:
        st.markdown("- " + r)

# ======================
# 3. Huáº¥n luyá»‡n & Ä‘Ã¡nh giÃ¡
# ======================
def train_and_evaluate(models, X_train, X_test, y_train, y_test):
    results = []
    cms = {}
    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        acc = accuracy_score(y_test, y_pred)
        prec = precision_score(y_test, y_pred, zero_division=0)
        rec = recall_score(y_test, y_pred, zero_division=0)
        f1 = f1_score(y_test, y_pred, zero_division=0)
        results.append({"MÃ´ hÃ¬nh": name, "Accuracy": acc, "Precision": prec, "Recall": rec, "F1-score": f1})
        cms[name] = confusion_matrix(y_test, y_pred)
    return pd.DataFrame(results), cms

# ======================
# Main pipeline (cháº¡y khi start app)
# ======================
file_path = "BTL/data/train.csv" #"E:/DangVanThanh/train.csv"    # sá»­a náº¿u cáº§n
df = load_and_prepare(file_path)

# TF-IDF
tfidf = TfidfVectorizer(stop_words='english', min_df=2, max_df=0.9, ngram_range=(1,2))
X = tfidf.fit_transform(df['text_clean'])
y = df['label'].values

# Train/Test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)

models = {
    "KNN (k=5)": KNeighborsClassifier(n_neighbors=5, n_jobs=-1),
    "Naive Bayes": MultinomialNB(),
    "Decision Tree": DecisionTreeClassifier(random_state=42)
}
results_df, cms = train_and_evaluate(models, X_train, X_test, y_train, y_test)

# LÆ°u TF-IDF vÃ  best model
joblib.dump(tfidf, "tfidf_vectorizer.pkl")
best_model_name = results_df.sort_values(by="F1-score", ascending=False).iloc[0]["MÃ´ hÃ¬nh"]
best_model = models[best_model_name]
joblib.dump(best_model, "best_model.pkl")

# ======================
# Streamlit UI: 3 tab
# ======================
st.set_page_config(page_title="Spam SMS Detector", layout="centered")
tab1, tab2, tab3 = st.tabs(["ğŸ“Š KhÃ¡m phÃ¡ dá»¯ liá»‡u", "ğŸ¤– Káº¿t quáº£ mÃ´ hÃ¬nh", "ğŸ“© Dá»± Ä‘oÃ¡n Spam/Ham"])

with tab1:
    st.header("ğŸ“Š KhÃ¡m phÃ¡ dá»¯ liá»‡u (EDA)")
    exploratory_data_analysis_streamlit(df)

with tab2:
    st.header("ğŸ¤– Káº¿t quáº£ mÃ´ hÃ¬nh")
    sorted_df = results_df.sort_values(by="F1-score", ascending=False).reset_index(drop=True)
    st.dataframe(sorted_df)

    # ======================
    # Hiá»ƒn thá»‹ hÃ¬nh áº£nh cho tá»«ng mÃ´ hÃ¬nh
    # ======================
    for name, model in models.items():
        st.subheader(f"Confusion Matrix - {name}")
        cm = cms[name]
        fig_cm, ax_cm = plt.subplots(figsize=(4,3))
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                    xticklabels=["Ham (0)", "Spam (1)"],
                    yticklabels=["Ham (0)", "Spam (1)"],
                    ax=ax_cm)
        st.pyplot(fig_cm)

        if name == "Decision Tree":
            st.subheader("ğŸŒ³ CÃ¢y quyáº¿t Ä‘á»‹nh (Decision Tree)")
            fig_tree, ax_tree = plt.subplots(figsize=(12, 6))
            tree.plot_tree(model,
                        filled=True,
                        class_names=["Ham", "Spam"],
                        max_depth=3,
                        fontsize=8,
                        ax=ax_tree)
            st.pyplot(fig_tree)
            st.caption("Giá»›i háº¡n depth=3 Ä‘á»ƒ cÃ¢y gá»n vÃ  dá»… quan sÃ¡t.")

        if hasattr(model, "predict_proba"):
            y_score = model.predict_proba(X_test)[:, 1]
            fpr, tpr, _ = roc_curve(y_test, y_score)
            roc_auc = auc(fpr, tpr)

            st.subheader(f"ğŸ“ˆ ROC Curve - {name}")
            fig_roc, ax_roc = plt.subplots(figsize=(4,3))
            ax_roc.plot(fpr, tpr, color="darkorange", lw=2, label=f"AUC = {roc_auc:.2f}")
            ax_roc.plot([0, 1], [0, 1], color="navy", lw=2, linestyle="--")
            ax_roc.set_xlim([0.0, 1.0])
            ax_roc.set_ylim([0.0, 1.05])
            ax_roc.set_xlabel("False Positive Rate")
            ax_roc.set_ylabel("True Positive Rate")
            ax_roc.set_title("ROC Curve")
            ax_roc.legend(loc="lower right")
            st.pyplot(fig_roc)

    # ======================
    # ğŸ“Š BÃ¡o cÃ¡o ngáº¯n tá»± Ä‘á»™ng (Ä‘áº·t cuá»‘i cÃ¹ng, chá»‰ hiá»‡n 1 láº§n)
    # ======================
    best_model = sorted_df.iloc[0]
    best_name = best_model['MÃ´ hÃ¬nh']
    best_clf = models[best_name]

    # Confusion Matrix (láº¥y giÃ¡ trá»‹ TP, TN, FP, FN)
    cm = cms[best_name]
    tn, fp, fn, tp = cm.ravel()

    # ROC AUC (náº¿u cÃ³ predict_proba)
    roc_auc = None
    if hasattr(best_clf, "predict_proba"):
        y_score = best_clf.predict_proba(X_test)[:, 1]
        fpr, tpr, _ = roc_curve(y_test, y_score)
        roc_auc = auc(fpr, tpr)

    # Táº¡o bÃ¡o cÃ¡o dáº¡ng báº£ng
    report_data = {
        "MÃ´ hÃ¬nh": [best_name],
        "Accuracy": [f"{best_model['Accuracy']:.2f}"],
        "Precision": [f"{best_model['Precision']:.2f}"],
        "Recall": [f"{best_model['Recall']:.2f}"],
        "F1-score": [f"{best_model['F1-score']:.2f}"],
        "TP": [tp],
        "TN": [tn],
        "FP": [fp],
        "FN": [fn],
        "ROC AUC": [f"{roc_auc:.2f}" if roc_auc else "N/A"]
    }

    st.subheader("ğŸ” BÃ¡o cÃ¡o tá»± Ä‘á»™ng - MÃ´ hÃ¬nh tá»‘t nháº¥t")
    st.table(pd.DataFrame(report_data))


with tab3:
    st.header("ğŸ“© Dá»± Ä‘oÃ¡n Spam/Ham")
    tfidf = joblib.load("tfidf_vectorizer.pkl")
    model = joblib.load("best_model.pkl")

    sms = st.text_area("Nháº­p tin nháº¯n:", height=150)
    if st.button("Dá»± Ä‘oÃ¡n"):
        if sms.strip() == "":
            st.warning("Báº¡n chÆ°a nháº­p tin nháº¯n!")
        else:
            sms_clean = clean_text(sms)
            X_new = tfidf.transform([sms_clean])
            y_pred = model.predict(X_new)[0]
            prob = None
            if hasattr(model, "predict_proba"):
                prob = model.predict_proba(X_new).max()
            if int(y_pred) == 1:
                st.error(f"ğŸš¨ Spam ({'%.2f'% (prob*100) + '%' if prob is not None else ''})")
            else:
                st.success(f"âœ… Ham ({'%.2f'% (prob*100) + '%' if prob is not None else ''})")
